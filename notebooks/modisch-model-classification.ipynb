{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 - Data Prep for Classification Model\n",
    "\n",
    "This notebook downloads the **Fashion-MNIST** dataset and reorganizes it from its 10 default classes into our project's 8 classes.\n",
    "\n",
    "**Our Target Classes:**\n",
    "* `jacket`\n",
    "* `shirt`\n",
    "* `pants`\n",
    "* `shorts`\n",
    "* `skirt`\n",
    "* `dress`\n",
    "* `shoe`\n",
    "* `slipper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "249fbdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls\n",
      "Data dir: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data\n",
      "Final Dataset dir: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch\n",
      "Kaggle Clothes source dir: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/clothes-dataset-unzipped\n",
      "Kaggle Shoes source dir: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/shoe-dataset-unzipped\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# Get project root\n",
    "CWD = pathlib.Path.cwd().resolve()\n",
    "PROJECT_ROOT = CWD.parent if CWD.name == \"notebooks\" else CWD\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "\n",
    "# Final organized dataset directory (for YOLO training)\n",
    "DATASET_DIR = DATA_DIR / \"dataset-fashion-modisch\"\n",
    "TRAIN_DIR = DATASET_DIR / \"train\"\n",
    "VAL_DIR = DATASET_DIR / \"val\"\n",
    "\n",
    "# Source Kaggle dataset paths\n",
    "CLOTHES_DATASET_SLUG = \"ryanbadai/clothes-dataset\"\n",
    "SHOE_DATASET_SLUG = \"noobyogi0100/shoe-dataset\"\n",
    "\n",
    "CLOTHES_ZIP = DATA_DIR / \"clothes-dataset.zip\"\n",
    "SHOES_ZIP = DATA_DIR / \"shoe-dataset.zip\"\n",
    "\n",
    "CLOTHES_SOURCE_DIR = DATA_DIR / \"clothes-dataset-unzipped\"\n",
    "SHOES_SOURCE_DIR = DATA_DIR / \"shoe-dataset-unzipped\"\n",
    "\n",
    "# Add src to path\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.append(str(SRC_DIR))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data dir: {DATA_DIR}\")\n",
    "print(f\"Final Dataset dir: {DATASET_DIR}\")\n",
    "print(f\"Kaggle Clothes source dir: {CLOTHES_SOURCE_DIR}\")\n",
    "print(f\"Kaggle Shoes source dir: {SHOES_SOURCE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af771e71",
   "metadata": {},
   "source": [
    "## Step 1: Download the Data\n",
    "\n",
    "We'll use the Ultralytics downloader to fetch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31c2f8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/macm4/.kaggle/kaggle.json'\n",
      "Authenticating\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /Users/macm4/.kaggle/kaggle.json'\n",
      "Authentication successful.\n",
      "Dataset URL: https://www.kaggle.com/datasets/ryanbadai/clothes-dataset\n",
      "Download complete: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/clothes-dataset.zip\n",
      "Downloading noobyogi0100/shoe-dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/noobyogi0100/shoe-dataset\n",
      "Download complete: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/clothes-dataset.zip\n",
      "Downloading noobyogi0100/shoe-dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/noobyogi0100/shoe-dataset\n",
      "Download complete: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/shoe-dataset.zip\n",
      "Unzipping clothes-dataset.zip...\n",
      "Download complete: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/shoe-dataset.zip\n",
      "Unzipping clothes-dataset.zip...\n",
      "Unzip complete to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/clothes-dataset-unzipped\n",
      "Unzipping shoe-dataset.zip...\n",
      "Unzip complete to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/clothes-dataset-unzipped\n",
      "Unzipping shoe-dataset.zip...\n",
      "Unzip complete to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/shoe-dataset-unzipped\n",
      "Unzip complete to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/shoe-dataset-unzipped\n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Authenticate and Download ---\n",
    "print(\"Authenticating\")\n",
    "try:\n",
    "    kaggle.api.authenticate()\n",
    "    print(\"Authentication successful.\")\n",
    "\n",
    "    # --- Download Clothes Dataset ---\n",
    "    if not CLOTHES_ZIP.exists():\n",
    "        kaggle.api.dataset_download_files(\n",
    "            CLOTHES_DATASET_SLUG,\n",
    "            path=DATA_DIR,\n",
    "            unzip=False  # Download as zip\n",
    "        )\n",
    "        # The Kaggle API often names the file after the dataset slug\n",
    "        # We must rename it to match our CLOTHES_ZIP path\n",
    "        downloaded_zip = DATA_DIR / f\"{CLOTHES_DATASET_SLUG.split('/')[-1]}.zip\"\n",
    "        if downloaded_zip.exists() and not CLOTHES_ZIP.exists():\n",
    "             downloaded_zip.rename(CLOTHES_ZIP)\n",
    "        print(f\"Download complete: {CLOTHES_ZIP}\")\n",
    "    else:\n",
    "        print(f\"{CLOTHES_ZIP.name} already downloaded.\")\n",
    "\n",
    "    # --- Download Shoe Dataset ---\n",
    "    if not SHOES_ZIP.exists():\n",
    "        print(f\"Downloading {SHOE_DATASET_SLUG}...\")\n",
    "        kaggle.api.dataset_download_files(\n",
    "            SHOE_DATASET_SLUG,\n",
    "            path=DATA_DIR,\n",
    "            unzip=False  # Download as zip\n",
    "        )\n",
    "        # Rename this zip file as well\n",
    "        downloaded_zip = DATA_DIR / f\"{SHOE_DATASET_SLUG.split('/')[-1]}.zip\"\n",
    "        if downloaded_zip.exists() and not SHOES_ZIP.exists():\n",
    "             downloaded_zip.rename(SHOES_ZIP)\n",
    "        print(f\"Download complete: {SHOES_ZIP}\")\n",
    "    else:\n",
    "        print(f\"{SHOES_ZIP.name} already downloaded.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Unzip Clothes Dataset\n",
    "CLOTHES_SOURCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "if not any(CLOTHES_SOURCE_DIR.iterdir()) and CLOTHES_ZIP.exists():\n",
    "    print(f\"Unzipping {CLOTHES_ZIP.name}...\")\n",
    "    with zipfile.ZipFile(CLOTHES_ZIP, 'r') as zf:\n",
    "        zf.extractall(CLOTHES_SOURCE_DIR)\n",
    "    print(f\"Unzip complete to: {CLOTHES_SOURCE_DIR}\")\n",
    "elif any(CLOTHES_SOURCE_DIR.iterdir()):\n",
    "    print(f\"Clothes dataset already unzipped at: {CLOTHES_SOURCE_DIR}\")\n",
    "else:\n",
    "    print(f\"Could not find {CLOTHES_ZIP.name} to unzip.\")\n",
    "\n",
    "# Unzip Shoe Dataset\n",
    "SHOES_SOURCE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "if not any(SHOES_SOURCE_DIR.iterdir()) and SHOES_ZIP.exists():\n",
    "    print(f\"Unzipping {SHOES_ZIP.name}...\")\n",
    "    with zipfile.ZipFile(SHOES_ZIP, 'r') as zf:\n",
    "        zf.extractall(SHOES_SOURCE_DIR)\n",
    "    print(f\"Unzip complete to: {SHOES_SOURCE_DIR}\")\n",
    "elif any(SHOES_SOURCE_DIR.iterdir()):\n",
    "    print(f\"Shoe dataset already unzipped at: {SHOES_SOURCE_DIR}\")\n",
    "else:\n",
    "    print(f\"Could not find {SHOES_ZIP.name} to unzip.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7be39a",
   "metadata": {},
   "source": [
    "## Step 3: Create Your New Class Folders\n",
    "\n",
    "This creates the `train` and `val` directories, each containing your 8 target class folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f38e041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new directory structure for 16 classes...\n",
      "New structure created.\n"
     ]
    }
   ],
   "source": [
    "# target class\n",
    "CLASSES_TO_CREATE = [\n",
    "    'boot', 'dress', 'pants', 'shirt', 'sneaker', 'flip-flop', 'loafer',\n",
    "    'short', 'skirt', 'slipper', 't-shirt', 'blazer', 'hoodie', 'jacket', 'sweater', 'polo'\n",
    "]\n",
    "\n",
    "print(f\"Creating new directory structure for {len(CLASSES_TO_CREATE)} classes...\")\n",
    "for split in [TRAIN_DIR, VAL_DIR]:\n",
    "    for cls_name in CLASSES_TO_CREATE:\n",
    "        os.makedirs(split / cls_name, exist_ok=True)\n",
    "\n",
    "print(\"New structure created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: \"Re-label\" by Moving Files\n",
    "\n",
    "This is the key step. We use terminal commands (`mv`) to move all images from the Fashion-MNIST folders (e.g., `T-shirt/top`) into your new folders (e.g., `shirt`).\n",
    "\n",
    "This works because we are in the `notebooks/` directory, so `../fashion-mnist` points to the unzipped folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc46a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping new Kaggle datasets and splitting into train/val...\n",
      "\n",
      "Processing Clothes Dataset from: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/clothes-dataset-unzipped\n",
      "  [Warning] Source folder not found: Blazer\n",
      "  [Warning] Source folder not found: Celana_Panjang\n",
      "  [Warning] Source folder not found: Celana_Pendek\n",
      "  [Warning] Source folder not found: Gaun\n",
      "  [Warning] Source folder not found: Hoodie\n",
      "  [Warning] Source folder not found: Jaket\n",
      "  [Warning] Source folder not found: Jaket_Denim\n",
      "  [Warning] Source folder not found: Jaket_Olahraga\n",
      "  [Warning] Source folder not found: Jeans\n",
      "  [Warning] Source folder not found: Kaos\n",
      "  [Warning] Source folder not found: Kemeja\n",
      "  [Warning] Source folder not found: Mantel\n",
      "  [Warning] Source folder not found: Polo\n",
      "  [Warning] Source folder not found: Rok\n",
      "  [Warning] Source folder not found: Sweter\n",
      "\n",
      "Processing Shoe Dataset from: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/shoe-dataset-unzipped\n",
      "  [Warning] Source folder not found: boots\n",
      "  [Warning] Source folder not found: sneakers\n",
      "  [Warning] Source folder not found: flip flops\n",
      "  [Warning] Source folder not found: loafers\n",
      "  [Warning] Source folder not found: sandals\n",
      "  [Warning] Source folder not found: soccer shoes\n",
      "\n",
      "--- File Move Complete ---\n",
      "Total Train Images: 0\n",
      "Total Val Images: 0\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Mapping new Kaggle datasets and splitting into train/val...\")\n",
    "\n",
    "# --- Mappings from Kaggle source folders to your 16 target class names ---\n",
    "\n",
    "# Target classes (as defined in the cell above)\n",
    "TARGET_CLASSES = set(CLASSES_TO_CREATE)\n",
    "\n",
    "# 1. ryanbadai/clothes-dataset\n",
    "CLOTHES_BASE_DIR = CLOTHES_SOURCE_DIR\n",
    "\n",
    "CLOTHES_MAP = {\n",
    "    \"Blazer\": \"blazer\",\n",
    "    \"Celana_Panjang\": \"pants\",\n",
    "    \"Celana_Pendek\": \"short\",\n",
    "    \"Gaun\": \"dress\",\n",
    "    \"Hoodie\": \"hoodie\",\n",
    "    \"Jaket\": \"jacket\",\n",
    "    \"Jaket_Denim\": \"jacket\",       # Grouped into 'jacket'\n",
    "    \"Jaket_Olahraga\": \"jacket\",    # Grouped into 'jacket'\n",
    "    \"Jeans\": \"pants\",          # Grouped into 'pants'\n",
    "    \"Kaos\": \"t-shirt\",\n",
    "    \"Kemeja\": \"shirt\",\n",
    "    \"Mantel\": \"jacket\",        # Grouped into 'jacket'\n",
    "    \"Polo\": \"polo\",\n",
    "    \"Rok\": \"skirt\",\n",
    "    \"Sweter\": \"sweater\",\n",
    "}\n",
    "\n",
    "# 2. noobyogi0100/shoe-dataset\n",
    "SHOES_BASE_DIR = SHOES_SOURCE_DIR\n",
    "\n",
    "SHOES_MAP = {\n",
    "    \"boots\": \"boot\",\n",
    "    \"sneakers\": \"sneaker\",\n",
    "    \"flip flops\": \"flip-flop\",\n",
    "    \"loafers\": \"loafer\",\n",
    "    \"sandals\": \"slipper\",      # Mapped to 'slipper'\n",
    "    \"soccer shoes\": \"sneaker\",     # Grouped into 'sneaker'\n",
    "}\n",
    "# --- End Mappings ---\n",
    "\n",
    "\n",
    "def split_and_copy_files(source_class_dir, target_class_name, train_dir, val_dir, split_ratio=0.8):\n",
    "    \"\"\"Copies files from source dir to train/val dirs with a split.\"\"\"\n",
    "    \n",
    "    if target_class_name not in TARGET_CLASSES:\n",
    "        print(f\"  [Skipping] Source '{source_class_dir.name}' maps to '{target_class_name}', which is not in TARGET_CLASSES.\")\n",
    "        return 0, 0\n",
    "\n",
    "    # Find all images (jpg, png, jpeg)\n",
    "    images = []\n",
    "    for ext in (\"*.jpg\", \"*.jpeg\", \"*.png\"):\n",
    "        images.extend(glob.glob(str(source_class_dir / ext)))\n",
    "    \n",
    "    if not images:\n",
    "        print(f\"  [Warning] No images found in {source_class_dir}\")\n",
    "        return 0, 0\n",
    "\n",
    "    random.seed(42) # for reproducible splits\n",
    "    random.shuffle(images)\n",
    "    split_point = int(len(images) * split_ratio)\n",
    "    train_files = images[:split_point]\n",
    "    val_files = images[split_point:]\n",
    "\n",
    "    # Get target directories\n",
    "    target_train_dir = train_dir / target_class_name\n",
    "    target_val_dir = val_dir / target_class_name\n",
    "\n",
    "    # Copy files\n",
    "    for f in train_files:\n",
    "        shutil.copy(f, target_train_dir / Path(f).name)\n",
    "    for f in val_files:\n",
    "        shutil.copy(f, target_val_dir / Path(f).name)\n",
    "        \n",
    "    return len(train_files), len(val_files)\n",
    "\n",
    "total_train = 0\n",
    "total_val = 0\n",
    "\n",
    "# --- Process Clothes Dataset ---\n",
    "print(f\"\\nProcessing Clothes Dataset from: {CLOTHES_BASE_DIR}\")\n",
    "for source_name, target_name in CLOTHES_MAP.items():\n",
    "    source_dir = CLOTHES_BASE_DIR / source_name\n",
    "    # Check for nested \"Clothes_Dataset\" folder\n",
    "    if not source_dir.exists():\n",
    "        nested_dir = CLOTHES_BASE_DIR / \"Clothes_Dataset\" / source_name\n",
    "        if nested_dir.exists():\n",
    "            source_dir = nested_dir\n",
    "        else:\n",
    "            print(f\"  [Warning] Source folder not found: {source_dir.name}\")\n",
    "            continue\n",
    "            \n",
    "    print(f\"Processing '{source_name}' -> '{target_name}'...\")\n",
    "    n_train, n_val = split_and_copy_files(source_dir, target_name, TRAIN_DIR, VAL_DIR)\n",
    "    print(f\"  Copied {n_train} train, {n_val} val files.\")\n",
    "    total_train += n_train\n",
    "    total_val += n_val\n",
    "\n",
    "# --- Process Shoe Dataset ---\n",
    "print(f\"\\nProcessing Shoe Dataset from: {SHOES_BASE_DIR}\")\n",
    "for source_name, target_name in SHOES_MAP.items():\n",
    "    source_dir = SHOES_BASE_DIR / source_name\n",
    "    if not source_dir.exists():\n",
    "        print(f\"  [Warning] Source folder not found: {source_dir.name}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing '{source_name}' -> '{target_name}'...\")\n",
    "    n_train, n_val = split_and_copy_files(source_dir, target_name, TRAIN_DIR, VAL_DIR)\n",
    "    print(f\"  Copied {n_train} train, {n_val} val files.\")\n",
    "    total_train += n_train\n",
    "    total_val += n_val\n",
    "\n",
    "print(\"\\n--- File Move Complete ---\")\n",
    "print(f\"Total Train Images: {total_train}\")\n",
    "print(f\"Total Val Images: {total_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: IMPORTANT - Check for Missing Classes\n",
    "\n",
    "The Fashion-MNIST dataset **does not contain** images for `shorts`, `skirt`, or `slipper`.\n",
    "\n",
    "Your folders for these classes are **empty**! You will need to find images for these classes and add them to the `train/` and `val/` subfolders yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9a5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5d: Oversample imbalanced classes in TRAIN_DIR (skirt, short/shorts)\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "TRAIN_DIR = pathlib.Path(TRAIN_DIR)  # ensure Path\n",
    "random.seed(42)\n",
    "\n",
    "TARGETS = [\n",
    "    'boot', 'dress', 'pants', 'shirt', 'sneaker', 'flip-flop', 'loafer',\n",
    "    'short', 'skirt', 'slipper', 't-shirt', 'blazer', 'hoodie', 'sweater', 'polo'\n",
    "]\n",
    "ALLOWED_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "# Optional PIL-based augmentation\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance, ImageOps\n",
    "    HAVE_PIL = True\n",
    "except Exception:\n",
    "    HAVE_PIL = False\n",
    "\n",
    "def _unique_path(dirpath: pathlib.Path, stem: str, ext: str) -> pathlib.Path:\n",
    "    i = 0\n",
    "    while True:\n",
    "        name = f\"{stem}_aug{'' if i==0 else f'_{i}'}{ext}\"\n",
    "        out = dirpath / name\n",
    "        if not out.exists():\n",
    "            return out\n",
    "        i += 1\n",
    "\n",
    "def _list_images(dirpath: pathlib.Path):\n",
    "    return [p for p in dirpath.glob(\"*\") if p.is_file() and p.suffix.lower() in ALLOWED_EXTS]\n",
    "\n",
    "def _pil_augment(img: \"Image.Image\") -> \"Image.Image\":\n",
    "    # simple, fast, safe transforms\n",
    "    if random.random() < 0.5:\n",
    "        img = ImageOps.mirror(img)\n",
    "    angle = random.uniform(-12, 12)\n",
    "    img = img.rotate(angle, resample=Image.BICUBIC, expand=False, fillcolor=(255, 255, 255))\n",
    "    # slight brightness/contrast jitter\n",
    "    img = ImageEnhance.Brightness(img).enhance(random.uniform(0.9, 1.1))\n",
    "    img = ImageEnhance.Contrast(img).enhance(random.uniform(0.9, 1.1))\n",
    "    return img\n",
    "\n",
    "def _augment_or_copy(src: pathlib.Path, dst: pathlib.Path):\n",
    "    if HAVE_PIL:\n",
    "        try:\n",
    "            with Image.open(src) as im:\n",
    "                if im.mode not in (\"RGB\", \"L\"):\n",
    "                    im = im.convert(\"RGB\")\n",
    "                # Save as same ext if supported; else default to .jpg\n",
    "                ext = dst.suffix.lower()\n",
    "                im = _pil_augment(im)\n",
    "                params = {}\n",
    "                if ext in {\".jpg\", \".jpeg\"}:\n",
    "                    params = {\"quality\": 90, \"optimize\": True}\n",
    "                im.save(dst, **params)\n",
    "                return\n",
    "        except Exception as _:\n",
    "            pass\n",
    "    # Fallback to raw copy\n",
    "    shutil.copy2(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fafece9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current train counts:\n",
      " - blazer    : 500\n",
      " - boot      : 249\n",
      " - dress     : 500\n",
      " - flip-flop : 249\n",
      " - hoodie    : 500\n",
      " - jacket    : 1995\n",
      " - loafer    : 249\n",
      " - pants     : 1000\n",
      " - polo      : 500\n",
      " - shirt     : 500\n",
      " - short     : 500\n",
      " - skirt     : 709\n",
      " - slipper   : 249\n",
      " - sneaker   : 478\n",
      " - sweater   : 500\n",
      " - t-shirt   : 500\n",
      "\n",
      "Oversampling to target count = 1995\n",
      " - boot: adding 1746 samples...\n",
      " - dress: adding 1495 samples...\n",
      " - pants: adding 995 samples...\n",
      " - shirt: adding 1495 samples...\n",
      " - sneaker: adding 1517 samples...\n",
      " - flip-flop: adding 1746 samples...\n",
      " - loafer: adding 1746 samples...\n",
      " - short: adding 1495 samples...\n",
      " - skirt: adding 1286 samples...\n",
      " - slipper: adding 1746 samples...\n",
      " - t-shirt: adding 1495 samples...\n",
      " - blazer: adding 1495 samples...\n",
      " - hoodie: adding 1495 samples...\n",
      " - sweater: adding 1495 samples...\n",
      " - polo: adding 1495 samples...\n",
      "\n",
      "Train counts after oversampling:\n",
      " - blazer    : 1995\n",
      " - boot      : 1995\n",
      " - dress     : 1995\n",
      " - flip-flop : 1995\n",
      " - hoodie    : 1995\n",
      " - jacket    : 1995\n",
      " - loafer    : 1995\n",
      " - pants     : 1995\n",
      " - polo      : 1995\n",
      " - shirt     : 1995\n",
      " - short     : 1995\n",
      " - skirt     : 1995\n",
      " - slipper   : 1995\n",
      " - sneaker   : 1995\n",
      " - sweater   : 1995\n",
      " - t-shirt   : 1995\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Count current train images per class (based on actual folders)\n",
    "class_dirs = [d for d in TRAIN_DIR.iterdir() if d.is_dir()]\n",
    "counts = {d.name: len(_list_images(d)) for d in class_dirs}\n",
    "print(\"Current train counts:\")\n",
    "for k in sorted(counts):\n",
    "    print(f\" - {k:10s}: {counts[k]}\")\n",
    "\n",
    "if not counts:\n",
    "    raise RuntimeError(\"No training classes found in TRAIN_DIR.\")\n",
    "\n",
    "target_count = max(counts.values())\n",
    "targets_existing = [c for c in TARGETS if (TRAIN_DIR / c).exists()]\n",
    "if not targets_existing:\n",
    "    print(\"No target classes (skirt/short/shorts) found in TRAIN_DIR. Skipping oversampling.\")\n",
    "else:\n",
    "    print(f\"\\nOversampling to target count = {target_count}\")\n",
    "    for cls in targets_existing:\n",
    "        cls_dir = TRAIN_DIR / cls\n",
    "        imgs = _list_images(cls_dir)\n",
    "        n = len(imgs)\n",
    "        if n == 0:\n",
    "            print(f\" - {cls}: no images to oversample from; add some first.\")\n",
    "            continue\n",
    "        need = target_count - n\n",
    "        if need <= 0:\n",
    "            print(f\" - {cls}: already >= target ({n} >= {target_count}).\")\n",
    "            continue\n",
    "\n",
    "        print(f\" - {cls}: adding {need} samples...\")\n",
    "        i = 0\n",
    "        while i < need:\n",
    "            src = random.choice(imgs)\n",
    "            stem = src.stem\n",
    "            ext = src.suffix.lower()\n",
    "            if ext not in ALLOWED_EXTS:\n",
    "                ext = \".jpg\"\n",
    "            dst = _unique_path(cls_dir, stem=stem, ext=ext)\n",
    "            _augment_or_copy(src, dst)\n",
    "            i += 1\n",
    "\n",
    "# Re-count after oversampling\n",
    "counts_after = {d.name: len(_list_images(d)) for d in class_dirs}\n",
    "print(\"\\nTrain counts after oversampling:\")\n",
    "for k in sorted(counts_after):\n",
    "    print(f\" - {k:10s}: {counts_after[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade6a49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts (train):\n",
      " - boot    : 1995\n",
      " - dress   : 1995\n",
      " - pants   : 1995\n",
      " - shirt   : 1995\n",
      " - sneaker : 1996\n",
      " - flip-flop: 1995\n",
      " - loafer  : 1995\n",
      " - short   : 1995\n",
      " - skirt   : 1995\n",
      " - slipper : 1995\n",
      " - t-shirt : 1995\n",
      " - blazer  : 1995\n",
      " - hoodie  : 1995\n",
      " - jacket  : 1995\n",
      " - sweater : 1995\n",
      " - polo    : 1995\n",
      "\n",
      "Class counts (val):\n",
      " - boot    : 50\n",
      " - dress   : 0\n",
      " - pants   : 0\n",
      " - shirt   : 0\n",
      " - sneaker : 95\n",
      " - flip-flop: 50\n",
      " - loafer  : 50\n",
      " - short   : 0\n",
      " - skirt   : 0\n",
      " - slipper : 50\n",
      " - t-shirt : 0\n",
      " - blazer  : 0\n",
      " - hoodie  : 0\n",
      " - jacket  : 0\n",
      " - sweater : 0\n",
      " - polo    : 0\n"
     ]
    }
   ],
   "source": [
    "# Count per-class files in train/ and val/\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_files(dirpath: pathlib.Path) -> dict:\n",
    "    counts = {}\n",
    "    for cls in CLASSES_TO_CREATE:\n",
    "        d = dirpath / cls\n",
    "        n = len([f for f in d.glob(\"*\") if f.is_file()]) if d.exists() else 0\n",
    "        counts[cls] = n\n",
    "    return counts\n",
    "\n",
    "train_counts = count_files(TRAIN_DIR)\n",
    "val_counts = count_files(VAL_DIR)\n",
    "\n",
    "print(\"Class counts (train):\")\n",
    "for k, v in train_counts.items():\n",
    "    print(f\" - {k:8s}: {v}\")\n",
    "\n",
    "print(\"\\nClass counts (val):\")\n",
    "for k, v in val_counts.items():\n",
    "    print(f\" - {k:8s}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5de23",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d497f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train classes: ['boot', 'dress', 'outer', 'pants', 'shirt', 'shoe', 'short', 'shorts', 'skirt', 'slipper', 't-shirt']\n",
      "Val classes: ['boot', 'dress', 'outer', 'pants', 'shirt', 'shoe', 'short', 'shorts', 'skirt', 'slipper', 't-shirt']\n"
     ]
    }
   ],
   "source": [
    "# --- Dataset sanity print: list classes in train/ and val/ (no syncing/moving) ---\n",
    "from pathlib import Path\n",
    "\n",
    "train_dir = TRAIN_DIR\n",
    "val_dir = VAL_DIR\n",
    "\n",
    "train_classes = sorted([d.name for d in Path(train_dir).iterdir() if d.is_dir()])\n",
    "val_classes = sorted([d.name for d in Path(val_dir).iterdir() if d.is_dir()])\n",
    "\n",
    "print(\"Train classes:\", train_classes)\n",
    "print(\"Val classes:\", val_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0736f2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['boot', 'dress', 'outer', 'pants', 'shirt', 'shoe', 'short', 'shorts', 'skirt', 'slipper', 't-shirt']\n",
      "Fixed empty splits: none\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "ALLOWED_EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "\n",
    "def list_images(dirpath: Path):\n",
    "    return [p for p in dirpath.glob(\"*\") if p.is_file() and p.suffix.lower() in ALLOWED_EXTS]\n",
    "\n",
    "train_dir = Path(TRAIN_DIR)\n",
    "val_dir = Path(VAL_DIR)\n",
    "\n",
    "train_classes = {d.name for d in train_dir.iterdir() if d.is_dir()}\n",
    "val_classes = {d.name for d in val_dir.iterdir() if d.is_dir()}\n",
    "all_classes = sorted(train_classes | val_classes)\n",
    "\n",
    "# Make sure each class exists in both splits\n",
    "for cls in all_classes:\n",
    "    (train_dir / cls).mkdir(parents=True, exist_ok=True)\n",
    "    (val_dir / cls).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Ensure at least 1 image per class per split by borrowing from the other split if needed\n",
    "fixed = []\n",
    "for cls in all_classes:\n",
    "    tr_imgs = list_images(train_dir / cls)\n",
    "    va_imgs = list_images(val_dir / cls)\n",
    "\n",
    "    if len(tr_imgs) == 0 and len(va_imgs) > 0:\n",
    "        src = random.choice(va_imgs)\n",
    "        dst = (train_dir / cls) / src.name\n",
    "        c = 1\n",
    "        while dst.exists():\n",
    "            dst = dst.with_name(f\"{src.stem}_{c}{src.suffix}\")\n",
    "            c += 1\n",
    "        shutil.copy2(src, dst)\n",
    "        fixed.append(f\"train/{cls}\")\n",
    "\n",
    "    if len(va_imgs) == 0 and len(tr_imgs) > 0:\n",
    "        src = random.choice(tr_imgs)\n",
    "        dst = (val_dir / cls) / src.name\n",
    "        c = 1\n",
    "        while dst.exists():\n",
    "            dst = dst.with_name(f\"{src.stem}_{c}{src.suffix}\")\n",
    "            c += 1\n",
    "        shutil.copy2(src, dst)\n",
    "        fixed.append(f\"val/{cls}\")\n",
    "\n",
    "print(\"Classes:\", all_classes)\n",
    "print(\"Fixed empty splits:\", fixed if fixed else \"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0246acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Per-epoch reporting WITHOUT touching DEFAULT_CFG (prevents YAML RepresenterError) ---\n",
    "from pathlib import Path\n",
    "\n",
    "REPORT_CSV = PROJECT_ROOT / \"runs-cls\" / \"epoch_report.csv\"\n",
    "\n",
    "def on_fit_epoch_end(trainer):\n",
    "    csv_path = Path(trainer.save_dir) / \"results.csv\"\n",
    "    if not csv_path.exists():\n",
    "        return\n",
    "    last = csv_path.read_text().strip().splitlines()[-1]\n",
    "    print(f\"[epoch {trainer.epoch + 1}] {last}\")\n",
    "    if not REPORT_CSV.exists():\n",
    "        header = csv_path.read_text().splitlines()[0]\n",
    "        REPORT_CSV.write_text(header + \"\\n\")\n",
    "    with REPORT_CSV.open(\"a\") as f:\n",
    "        f.write(last + \"\\n\")\n",
    "\n",
    "def register_callbacks(model):\n",
    "    # avoid duplicate registration if re-running cells\n",
    "    try:\n",
    "        model.remove_callback(\"on_fit_epoch_end\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    model.add_callback(\"on_fit_epoch_end\", on_fit_epoch_end)\n",
    "    print(\"Per-epoch report callback registered. Writing mirror CSV to:\", REPORT_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a263e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Per-epoch report callback registered. Writing mirror CSV to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/epoch_report.csv\n",
      "Per-epoch report callback registered. Writing mirror CSV to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/epoch_report.csv\n",
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 MPS (Apple M4)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n-cls-fashion5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 MPS (Apple M4)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch, degrees=0.0, deterministic=True, device=mps, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n-cls-fashion5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=False, pose=12.0, pretrained=True, profile=False, project=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/train... found 78000 images in 10 classes (requires 11 classes, not 10)\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/train... found 78000 images in 10 classes (requires 11 classes, not 10)\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/val... found 9042 images in 10 classes (requires 11 classes, not 10)\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/val... found 9042 images in 10 classes (requires 11 classes, not 10)\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "Overriding model.yaml nc=1000 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    344331  ultralytics.nn.modules.head.Classify         [256, 11]                     \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    344331  ultralytics.nn.modules.head.Classify         [256, 11]                     \n",
      "YOLOv8n-cls summary: 56 layers, 1,452,379 parameters, 1,452,379 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "YOLOv8n-cls summary: 56 layers, 1,452,379 parameters, 1,452,379 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1.1¬±0.5 MB/s, size: 0.5 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1.1¬±0.5 MB/s, size: 0.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/train... 78000 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 78000/78000 115.0Mit/s 0.0s\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1.6¬±0.9 MB/s, size: 0.5 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1.6¬±0.9 MB/s, size: 0.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/val... 9042 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9042/9042 20.2Mit/s 0.0s\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       1/30      1.11G      0.911         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.2it/s 9:25<0.6s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.6it/s 19.7s0.3s\n",
      "                   all      0.815      0.999\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.6it/s 19.7s\n",
      "                   all      0.815      0.999\n",
      "[epoch 1] 1,584.817,0.911,0.81486,0.99867,0.48706,0.0033306,0.0033306,0.0033306\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 1] 1,584.817,0.911,0.81486,0.99867,0.48706,0.0033306,0.0033306,0.0033306\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       2/30      2.12G     0.3658         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.0it/s 10:07<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.9it/s 18.3s0.2s\n",
      "                   all      0.873      0.999\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.9it/s 18.3s\n",
      "                   all      0.873      0.999\n",
      "[epoch 2] 2,1215.28,0.36578,0.87282,0.99945,0.34695,0.00644402,0.00644402,0.00644402\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 2] 2,1215.28,0.36578,0.87282,0.99945,0.34695,0.00644402,0.00644402,0.00644402\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       3/30      2.12G     0.3016         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.3it/s 8:50<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.7it/s 19.0s0.3s\n",
      "                   all      0.881          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.7it/s 19.0s\n",
      "                   all      0.881          1\n",
      "[epoch 3] 3,1765.3,0.30157,0.88056,0.99956,0.32224,0.00933745,0.00933745,0.00933745\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 3] 3,1765.3,0.30157,0.88056,0.99956,0.32224,0.00933745,0.00933745,0.00933745\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       4/30      1.12G     0.2724         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.7it/s 7:24<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.4it/s 16.3s0.2s\n",
      "                   all       0.91          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.4it/s 16.3s\n",
      "                   all       0.91          1\n",
      "[epoch 4] 4,2226.27,0.2724,0.90998,0.99978,0.24328,0.00901,0.00901,0.00901\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 4] 4,2226.27,0.2724,0.90998,0.99978,0.24328,0.00901,0.00901,0.00901\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       5/30      1.12G     0.2424         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.8it/s 7:15<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.9it/s 14.5s0.2s\n",
      "                   all      0.913          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.9it/s 14.5s\n",
      "                   all      0.913          1\n",
      "[epoch 5] 5,2676.13,0.24242,0.91307,0.99989,0.22684,0.00868,0.00868,0.00868\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 5] 5,2676.13,0.24242,0.91307,0.99989,0.22684,0.00868,0.00868,0.00868\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       6/30      1.12G      0.224         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.9it/s 6:56<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.3it/s 16.6s0.2s\n",
      "                   all      0.923          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.3it/s 16.6s\n",
      "                   all      0.923          1\n",
      "[epoch 6] 6,3108.98,0.22398,0.92269,0.99978,0.20553,0.00835,0.00835,0.00835\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 6] 6,3108.98,0.22398,0.92269,0.99978,0.20553,0.00835,0.00835,0.00835\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       7/30      1.12G     0.2146         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.8it/s 7:14<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.4it/s 16.2s0.2s\n",
      "                   all      0.928          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.4it/s 16.2s\n",
      "                   all      0.928          1\n",
      "[epoch 7] 7,3559.45,0.21462,0.92811,0.99967,0.19741,0.00802,0.00802,0.00802\n",
      "[epoch 7] 7,3559.45,0.21462,0.92811,0.99967,0.19741,0.00802,0.00802,0.00802\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       8/30      2.12G     0.2084         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.9it/s 6:54<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.6it/s 15.4s0.2s\n",
      "                   all      0.931          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.6it/s 15.4s\n",
      "                   all      0.931          1\n",
      "[epoch 8] 8,3989.07,0.20841,0.93132,0.99978,0.18668,0.00769,0.00769,0.00769\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 8] 8,3989.07,0.20841,0.93132,0.99978,0.18668,0.00769,0.00769,0.00769\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K       9/30      2.12G     0.2026         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 3.2it/s 6:23<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.3it/s 16.4s0.2s\n",
      "                   all      0.934          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.3it/s 16.4s\n",
      "                   all      0.934          1\n",
      "[epoch 9] 9,4388.89,0.20259,0.93442,0.99978,0.18253,0.00736,0.00736,0.00736\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 9] 9,4388.89,0.20259,0.93442,0.99978,0.18253,0.00736,0.00736,0.00736\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      10/30      2.12G     0.1967         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 3.0it/s 6:51<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 5.4it/s 13.3s0.2s\n",
      "                   all      0.934          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 5.4it/s 13.3s\n",
      "                   all      0.934          1\n",
      "[epoch 10] 10,4813.75,0.19669,0.9342,0.99978,0.17672,0.00703,0.00703,0.00703\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 10] 10,4813.75,0.19669,0.9342,0.99978,0.17672,0.00703,0.00703,0.00703\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      11/30      2.12G     0.1928         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 3.1it/s 6:39<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 5.1it/s 14.0s0.2s\n",
      "                   all      0.936          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 5.1it/s 14.0s\n",
      "                   all      0.936          1\n",
      "[epoch 11] 11,5226.92,0.19279,0.9363,0.99989,0.17471,0.0067,0.0067,0.0067\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 11] 11,5226.92,0.19279,0.9363,0.99989,0.17471,0.0067,0.0067,0.0067\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      12/30      2.12G     0.1884         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 3.0it/s 6:52<0.3s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.2it/s 16.9s0.2s\n",
      "                   all      0.938          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.2it/s 16.9s\n",
      "                   all      0.938          1\n",
      "[epoch 12] 12,5656.19,0.18835,0.93751,0.99989,0.16934,0.00637,0.00637,0.00637\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 12] 12,5656.19,0.18835,0.93751,0.99989,0.16934,0.00637,0.00637,0.00637\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      13/30      2.11G     0.1884         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.7it/s 7:32<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.4it/s 20.7s0.3s\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.4it/s 20.7s\n",
      "                   all       0.94          1\n",
      "                   all       0.94          1\n",
      "[epoch 13] 13,6129.62,0.18843,0.94006,0.99978,0.16574,0.00604,0.00604,0.00604\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 13] 13,6129.62,0.18843,0.94006,0.99978,0.16574,0.00604,0.00604,0.00604\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      14/30      1.12G      0.184         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.3it/s 8:60<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.6it/s 19.9s0.3ss\n",
      "                   all       0.94          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.6it/s 19.9s\n",
      "                   all       0.94          1\n",
      "[epoch 14] 14,6689.87,0.18402,0.94017,0.99978,0.16379,0.00571,0.00571,0.00571\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 14] 14,6689.87,0.18402,0.94017,0.99978,0.16379,0.00571,0.00571,0.00571\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      15/30      1.12G     0.1803         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 1.9it/s 10:32<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.0it/s 17.7s0.3s\n",
      "                   all      0.941          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.0it/s 17.7s\n",
      "                   all      0.941          1\n",
      "[epoch 15] 15,7340.71,0.18031,0.94061,0.99978,0.16267,0.00538,0.00538,0.00538\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 15] 15,7340.71,0.18031,0.94061,0.99978,0.16267,0.00538,0.00538,0.00538\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      16/30      1.12G     0.1778         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.4it/s 8:35<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.7it/s 19.3s0.3s\n",
      "                   all      0.941          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.7it/s 19.3s\n",
      "                   all      0.941          1\n",
      "[epoch 16] 16,7875.75,0.17779,0.9415,0.99989,0.16076,0.00505,0.00505,0.00505\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 16] 16,7875.75,0.17779,0.9415,0.99989,0.16076,0.00505,0.00505,0.00505\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      17/30      1.12G     0.1722         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.0it/s 10:11<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.5s0.3s\n",
      "                   all      0.942          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.5s\n",
      "                   all      0.942          1\n",
      "[epoch 17] 17,8505.22,0.17219,0.94183,0.99989,0.16005,0.00472,0.00472,0.00472\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 17] 17,8505.22,0.17219,0.94183,0.99989,0.16005,0.00472,0.00472,0.00472\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      18/30      1.12G     0.1693         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 8:01<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.5s0.3s\n",
      "                   all      0.942          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.5s\n",
      "                   all      0.942          1\n",
      "[epoch 18] 18,9004.03,0.16931,0.94194,0.99978,0.15895,0.00439,0.00439,0.00439\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 18] 18,9004.03,0.16931,0.94194,0.99978,0.15895,0.00439,0.00439,0.00439\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      19/30      1.12G     0.1636         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 7:59<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.0it/s 17.7s0.3s\n",
      "                   all      0.943          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.0it/s 17.7s\n",
      "                   all      0.943          1\n",
      "[epoch 19] 19,9500.83,0.16364,0.94338,0.99989,0.15846,0.00406,0.00406,0.00406\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 19] 19,9500.83,0.16364,0.94338,0.99989,0.15846,0.00406,0.00406,0.00406\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      20/30      1.12G     0.1621         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 8:01<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.4s0.2s\n",
      "                   all      0.943          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.4s\n",
      "                   all      0.943          1\n",
      "[epoch 20] 20,10000,0.16205,0.94304,0.99989,0.1577,0.00373,0.00373,0.00373\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 20] 20,10000,0.16205,0.94304,0.99989,0.1577,0.00373,0.00373,0.00373\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      21/30      1.12G     0.1552         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 7:59<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.4s0.2s\n",
      "                   all      0.944          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.4s\n",
      "                   all      0.944          1\n",
      "[epoch 21] 21,10497,0.15521,0.94404,0.99989,0.15655,0.0034,0.0034,0.0034\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 21] 21,10497,0.15521,0.94404,0.99989,0.15655,0.0034,0.0034,0.0034\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      22/30      1.12G     0.1514         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 8:01<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.9it/s 18.1s0.2s\n",
      "                   all      0.945          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 3.9it/s 18.1s\n",
      "                   all      0.945          1\n",
      "[epoch 22] 22,10996.2,0.15144,0.94526,0.99989,0.15521,0.00307,0.00307,0.00307\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 22] 22,10996.2,0.15144,0.94526,0.99989,0.15521,0.00307,0.00307,0.00307\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      23/30      1.12G     0.1493         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 8:00<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.4s0.2s\n",
      "                   all      0.946          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.4s\n",
      "                   all      0.946          1\n",
      "[epoch 23] 23,11494.2,0.14929,0.94559,0.99989,0.15448,0.00274,0.00274,0.00274\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 23] 23,11494.2,0.14929,0.94559,0.99989,0.15448,0.00274,0.00274,0.00274\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      24/30      1.12G     0.1405         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 7:60<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.3s0.2s\n",
      "                   all      0.945          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.3s\n",
      "                   all      0.945          1\n",
      "[epoch 24] 24,11992.1,0.14045,0.94503,0.99989,0.15374,0.00241,0.00241,0.00241\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 24] 24,11992.1,0.14045,0.94503,0.99989,0.15374,0.00241,0.00241,0.00241\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      25/30      1.12G     0.1381         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 7:60<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.5s0.2s\n",
      "                   all      0.945          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.5s\n",
      "                   all      0.945          1\n",
      "[epoch 25] 25,12489.8,0.13815,0.94526,0.99989,0.15267,0.00208,0.00208,0.00208\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 25] 25,12489.8,0.13815,0.94526,0.99989,0.15267,0.00208,0.00208,0.00208\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      26/30      1.12G     0.1307         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 8:00<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.3s0.2s\n",
      "                   all      0.945          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.3s\n",
      "                   all      0.945          1\n",
      "[epoch 26] 26,12987.8,0.13071,0.94492,0.99989,0.15147,0.00175,0.00175,0.00175\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 26] 26,12987.8,0.13071,0.94492,0.99989,0.15147,0.00175,0.00175,0.00175\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      27/30      1.12G     0.1253         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 8:01<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.4s0.3s\n",
      "                   all      0.945          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.4s\n",
      "                   all      0.945          1\n",
      "[epoch 27] 27,13487.3,0.12529,0.94514,0.99989,0.15164,0.00142,0.00142,0.00142\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 27] 27,13487.3,0.12529,0.94514,0.99989,0.15164,0.00142,0.00142,0.00142\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      28/30      1.12G     0.1194         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 7:60<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.0it/s 17.6s0.3s\n",
      "                   all      0.946          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.0it/s 17.6s\n",
      "                   all      0.946          1\n",
      "[epoch 28] 28,13985.3,0.11939,0.94581,0.99989,0.14923,0.00109,0.00109,0.00109\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 28] 28,13985.3,0.11939,0.94581,0.99989,0.14923,0.00109,0.00109,0.00109\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      29/30      1.12G      0.115         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 8:02<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.5s0.3s\n",
      "                   all      0.946          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.5s\n",
      "                   all      0.946          1\n",
      "[epoch 29] 29,14485.6,0.11505,0.94559,0.99989,0.14914,0.00076,0.00076,0.00076\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "[epoch 29] 29,14485.6,0.11505,0.94559,0.99989,0.14914,0.00076,0.00076,0.00076\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n",
      "\u001b[K      30/30      1.12G     0.1123         48        224: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1219/1219 2.5it/s 8:00<0.4s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.3s0.2s\n",
      "                   all      0.946          1\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.1it/s 17.3s\n",
      "                   all      0.946          1\n",
      "[epoch 30] 30,14983.8,0.11229,0.94603,0.99989,0.14757,0.00043,0.00043,0.00043\n",
      "\n",
      "30 epochs completed in 4.162 hours.\n",
      "[epoch 30] 30,14983.8,0.11229,0.94603,0.99989,0.14757,0.00043,0.00043,0.00043\n",
      "\n",
      "30 epochs completed in 4.162 hours.\n",
      "Optimizer stripped from /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.pt...\n",
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 MPS (Apple M4)\n",
      "Optimizer stripped from /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.pt...\n",
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 MPS (Apple M4)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,448,971 parameters, 0 gradients, 3.3 GFLOPs\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,448,971 parameters, 0 gradients, 3.3 GFLOPs\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/train... found 78000 images in 10 classes (requires 11 classes, not 10)\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/train... found 78000 images in 10 classes (requires 11 classes, not 10)\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/val... found 9042 images in 10 classes (requires 11 classes, not 10)\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/val... found 9042 images in 10 classes (requires 11 classes, not 10)\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.7it/s 15.2s0.2s\n",
      "                   all      0.946          1\n",
      "Speed: 0.0ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 71/71 4.7it/s 15.2s\n",
      "                   all      0.946          1\n",
      "Speed: 0.0ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "[epoch 30] 30,14983.8,0.11229,0.94603,0.99989,0.14757,0.00043,0.00043,0.00043\n",
      "[epoch 30] 30,14983.8,0.11229,0.94603,0.99989,0.14757,0.00043,0.00043,0.00043\n",
      "Best weights: see run dir for weights\n",
      "Best weights: see run dir for weights\n"
     ]
    }
   ],
   "source": [
    "# --- Train YOLOv8n-cls (MPS if available) ---\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.utils import DEFAULT_CFG\n",
    "import os\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "# Remove any default callbacks so the 'callbacks' key doesn't leak into args.yaml/cfg\n",
    "try:\n",
    "    if hasattr(DEFAULT_CFG, \"callbacks\"):\n",
    "        delattr(DEFAULT_CFG, \"callbacks\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "DEVICE = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "NUM_WORKERS = 4\n",
    "BATCH = 64\n",
    "\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "model = YOLO(\"yolov8n-cls.pt\")\n",
    "\n",
    "# Extra safety: strip any 'callbacks' from model overrides if present\n",
    "try:\n",
    "    if hasattr(model, \"overrides\") and isinstance(model.overrides, dict):\n",
    "        model.overrides.pop(\"callbacks\", None)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Register console/CSV epoch reporter on the model only (not in DEFAULT_CFG)\n",
    "try:\n",
    "    register_callbacks(model)\n",
    "except NameError:\n",
    "    REPORT_CSV = PROJECT_ROOT / \"runs-cls\" / \"epoch_report.csv\"\n",
    "    def _on_fit_epoch_end(trainer):\n",
    "        csv_path = Path(trainer.save_dir) / \"results.csv\"\n",
    "        if not csv_path.exists():\n",
    "            return\n",
    "        last = csv_path.read_text().strip().splitlines()[-1]\n",
    "        print(f\"[epoch {trainer.epoch + 1}] {last}\")\n",
    "        if not REPORT_CSV.exists():\n",
    "            header = csv_path.read_text().splitlines()[0]\n",
    "            REPORT_CSV.write_text(header + \"\\n\")\n",
    "        with REPORT_CSV.open(\"a\") as f:\n",
    "            f.write(last + \"\\n\")\n",
    "    try:\n",
    "        model.remove_callback(\"on_fit_epoch_end\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    model.add_callback(\"on_fit_epoch_end\", _on_fit_epoch_end)\n",
    "    print(\"Per-epoch report callback registered. Writing mirror CSV to:\", REPORT_CSV)\n",
    "\n",
    "RUNS_DIR = PROJECT_ROOT / \"runs-cls\"\n",
    "NAME = \"yolov8n-cls-fashion\"\n",
    "EPOCHS = 30\n",
    "IMGSZ = 224\n",
    "SEED = 42\n",
    "\n",
    "results = model.train(\n",
    "    data=str(DATASET_DIR),\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMGSZ,\n",
    "    batch=BATCH,\n",
    "    project=str(RUNS_DIR),\n",
    "    name=NAME,\n",
    "    seed=SEED,\n",
    "    patience=10,         # early stopping\n",
    "    verbose=True,\n",
    "    device=DEVICE,\n",
    "    workers=NUM_WORKERS,\n",
    "    plots=False,\n",
    ")\n",
    "\n",
    "best_path = RUNS_DIR / NAME / \"weights\" / \"best.pt\"\n",
    "print(\"Best weights:\", best_path if best_path.exists() else \"see run dir for weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5f476ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 CPU (Apple M4)\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,448,971 parameters, 0 gradients, 3.3 GFLOPs\n",
      "YOLOv8n-cls summary (fused): 30 layers, 1,448,971 parameters, 0 gradients, 3.3 GFLOPs\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/train... found 78000 images in 10 classes (requires 11 classes, not 10)\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mtrain:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/train... found 78000 images in 10 classes (requires 11 classes, not 10)\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/val... found 9042 images in 10 classes (requires 11 classes, not 10)\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "ERROR ‚ùå \u001b[34m\u001b[1mval:\u001b[0m /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/val... found 9042 images in 10 classes (requires 11 classes, not 10)\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1.7¬±0.6 MB/s, size: 0.5 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1.7¬±0.6 MB/s, size: 0.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch/val... 9042 images, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9042/9042 18.2Mit/s 0.0s\n",
      "\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 142/142 1.4it/s 1:390.7ss\n",
      "\u001b[K               classes   top1_acc   top5_acc: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 142/142 1.4it/s 1:39\n",
      "                   all      0.946          1\n",
      "Speed: 0.0ms preprocess, 9.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion-val\u001b[0m\n",
      "top1: 0.9460, top5: 0.9999\n",
      "Val plots saved to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion-val\n",
      "                   all      0.946          1\n",
      "Speed: 0.0ms preprocess, 9.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion-val\u001b[0m\n",
      "top1: 0.9460, top5: 0.9999\n",
      "Val plots saved to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion-val\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(\n",
    "    data=str(DATASET_DIR),\n",
    "    imgsz=IMGSZ,\n",
    "    batch=BATCH,\n",
    "    plots=True,\n",
    "    project=str(RUNS_DIR),\n",
    "    name=NAME + \"-val\",\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(f\"top1: {metrics.top1:.4f}, top5: {metrics.top5:.4f}\")\n",
    "except Exception:\n",
    "    print(\"Validation metrics:\", metrics)\n",
    "print(\"Val plots saved to:\", RUNS_DIR / (NAME + \"-val\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8355b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion-pred\u001b[0m\n",
      "Saved predictions to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion-pred\n",
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 CPU (Apple M4)\n",
      "Saved predictions to: /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion-pred\n",
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 CPU (Apple M4)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 11) (2.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 11) (2.8 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0', 'onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.19.1-cp311-cp311-macosx_12_0_universal2.whl.metadata (7.0 kB)\n",
      "Collecting onnxslim>=0.1.71\n",
      "  Downloading onnxslim-0.1.72-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.23.2-cp311-cp311-macosx_13_0_arm64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnx>=1.12.0) (2.2.6)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnx>=1.12.0) (6.33.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnx>=1.12.0) (4.15.0)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx>=1.12.0)\n",
      "  Downloading ml_dtypes-0.5.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnxslim>=0.1.71) (1.14.0)\n",
      "Requirement already satisfied: packaging in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnxslim>=0.1.71) (25.0)\n",
      "Collecting colorama (from onnxslim>=0.1.71)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->onnxslim>=0.1.71) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Downloading onnx-1.19.1-cp311-cp311-macosx_12_0_universal2.whl (18.3 MB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/18.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/18.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/18.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/18.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/18.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/18.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.1/18.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/18.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.7/18.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.3/18.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.6/18.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.9/18.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.3/18.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m17.6/18.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading onnxslim-0.1.72-py3-none-any.whl (165 kB)\n",
      "Downloading onnxruntime-1.23.2-cp311-cp311-macosx_13_0_arm64.whl (17.2 MB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/17.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/17.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/17.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/17.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/17.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.1/17.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.4/17.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.7/17.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.0/17.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.3/17.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.6/17.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.9/17.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.9/17.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ\u001b[0m \u001b[32m16.0/17.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp311-cp311-macosx_10_9_universal2.whl (667 kB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/667.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m667.4/667.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, ml_dtypes, humanfriendly, colorama, onnx, coloredlogs, onnxslim, onnxruntime\n",
      "\u001b[?25l\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6/8\u001b[0m [onnxslim]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/8\u001b[0m [onnxruntime]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/8\u001b[0m [onnxruntime]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/8\u001b[0m [onnxruntime]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/8\u001b[0m [onnxruntime]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8/8\u001b[0m [onnxruntime]\n",
      "\u001b[?25h\n",
      "\u001b[1A\u001b[2KSuccessfully installed colorama-0.4.6 coloredlogs-15.0.1 flatbuffers-25.9.23 humanfriendly-10.0 ml_dtypes-0.5.3 onnx-1.19.1 onnxruntime-1.23.2 onnxslim-0.1.72\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 13.0s\n",
      "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "Collecting onnx>=1.12.0\n",
      "  Downloading onnx-1.19.1-cp311-cp311-macosx_12_0_universal2.whl.metadata (7.0 kB)\n",
      "Collecting onnxslim>=0.1.71\n",
      "  Downloading onnxslim-0.1.72-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.23.2-cp311-cp311-macosx_13_0_arm64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnx>=1.12.0) (2.2.6)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnx>=1.12.0) (6.33.0)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnx>=1.12.0) (4.15.0)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx>=1.12.0)\n",
      "  Downloading ml_dtypes-0.5.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnxslim>=0.1.71) (1.14.0)\n",
      "Requirement already satisfied: packaging in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from onnxslim>=0.1.71) (25.0)\n",
      "Collecting colorama (from onnxslim>=0.1.71)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/macm4/repositories/Machine Learning Model/modisch-model-cls/.venv/lib/python3.11/site-packages (from sympy>=1.13.3->onnxslim>=0.1.71) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Downloading onnx-1.19.1-cp311-cp311-macosx_12_0_universal2.whl (18.3 MB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/18.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/18.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/18.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/18.3 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/18.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.8/18.3 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.1/18.3 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/18.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.7/18.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.3/18.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.6/18.3 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.9/18.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.3/18.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ\u001b[0m \u001b[32m17.6/18.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading onnxslim-0.1.72-py3-none-any.whl (165 kB)\n",
      "Downloading onnxruntime-1.23.2-cp311-cp311-macosx_13_0_arm64.whl (17.2 MB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/17.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/17.2 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/17.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/17.2 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.5/17.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.1/17.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.4/17.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.7/17.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.0/17.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.3/17.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.6/17.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.9/17.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.9/17.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ\u001b[0m \u001b[32m16.0/17.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp311-cp311-macosx_10_9_universal2.whl (667 kB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/667.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m667.4/667.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, ml_dtypes, humanfriendly, colorama, onnx, coloredlogs, onnxslim, onnxruntime\n",
      "\u001b[?25l\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/8\u001b[0m [onnx]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6/8\u001b[0m [onnxslim]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/8\u001b[0m [onnxruntime]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/8\u001b[0m [onnxruntime]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/8\u001b[0m [onnxruntime]\n",
      "\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7/8\u001b[0m [onnxruntime]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8/8\u001b[0m [onnxruntime]\n",
      "\u001b[?25h\n",
      "\u001b[1A\u001b[2KSuccessfully installed colorama-0.4.6 coloredlogs-15.0.1 flatbuffers-25.9.23 humanfriendly-10.0 ml_dtypes-0.5.3 onnx-1.19.1 onnxruntime-1.23.2 onnxslim-0.1.72\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 13.0s\n",
      "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.72...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.72...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 16.4s, saved as '/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.onnx' (5.6 MB)\n",
      "\n",
      "Export complete (16.4s)\n",
      "Results saved to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.onnx imgsz=224  \n",
      "Validate:        yolo val task=classify model=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.onnx imgsz=224 data=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch  \n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 CPU (Apple M4)\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 16.4s, saved as '/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.onnx' (5.6 MB)\n",
      "\n",
      "Export complete (16.4s)\n",
      "Results saved to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.onnx imgsz=224  \n",
      "Validate:        yolo val task=classify model=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.onnx imgsz=224 data=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch  \n",
      "Visualize:       https://netron.app\n",
      "Ultralytics 8.3.223 üöÄ Python-3.11.14 torch-2.9.0 CPU (Apple M4)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 11) (2.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.pt' with input shape (1, 3, 224, 224) BCHW and output shape(s) (1, 11) (2.8 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.9.0...\n",
      "\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.9.0...\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 0.4s, saved as '/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.torchscript' (5.7 MB)\n",
      "\n",
      "Export complete (0.4s)\n",
      "Results saved to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.torchscript imgsz=224  \n",
      "Validate:        yolo val task=classify model=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.torchscript imgsz=224 data=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch  \n",
      "Visualize:       https://netron.app\n",
      "Exported ONNX and TorchScript.\n",
      "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 0.4s, saved as '/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.torchscript' (5.7 MB)\n",
      "\n",
      "Export complete (0.4s)\n",
      "Results saved to \u001b[1m/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights\u001b[0m\n",
      "Predict:         yolo predict task=classify model=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.torchscript imgsz=224  \n",
      "Validate:        yolo val task=classify model=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/runs-cls/yolov8n-cls-fashion5/weights/best.torchscript imgsz=224 data=/Users/macm4/repositories/Machine Learning Model/modisch-model-cls/data/dataset-fashion-modisch  \n",
      "Visualize:       https://netron.app\n",
      "Exported ONNX and TorchScript.\n"
     ]
    }
   ],
   "source": [
    "TEST_DIR = PROJECT_ROOT / \"test\"\n",
    "\n",
    "preds = model.predict(\n",
    "    source=str(TEST_DIR),\n",
    "    imgsz=IMGSZ,\n",
    "    save=True,\n",
    "    project=str(RUNS_DIR),\n",
    "    name=NAME + \"-pred\",\n",
    "    verbose=False,\n",
    ")\n",
    "print(\"Saved predictions to:\", RUNS_DIR / (NAME + \"-pred\"))\n",
    "\n",
    "# Optional exports for deployment\n",
    "try:\n",
    "    model.export(format=\"onnx\", opset=12)\n",
    "    model.export(format=\"torchscript\")\n",
    "    print(\"Exported ONNX and TorchScript.\")\n",
    "except Exception as e:\n",
    "    print(\"Export skipped:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
